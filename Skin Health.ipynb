{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Wn9dRyJ6MRS5J-NQ1MSmJenm6dy0GNqt","authorship_tag":"ABX9TyMeKVZ4rdRkBK/2nzdFKVOc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Skin Anomaly Detection**"],"metadata":{"id":"b22S-8Vb2RTm"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4veA20qj93R","executionInfo":{"status":"ok","timestamp":1722244005504,"user_tz":-420,"elapsed":3098,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}},"outputId":"5cd16870-dcae-4978-baf0-9330c3505315"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["pip install pandas numpy opencv-python tensorflow scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8CBCNM7fnjkW","executionInfo":{"status":"ok","timestamp":1722244016549,"user_tz":-420,"elapsed":11049,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}},"outputId":"18e69610-a126-4535-ebc7-2e8545ce1f3f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","source":["import os\n","import zipfile\n","import pandas as pd\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, fbeta_score"],"metadata":{"id":"yg2ztYXlvZKG","executionInfo":{"status":"ok","timestamp":1722244016549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Extract zip files\n","zip_paths = ['/content/drive/MyDrive/Skeenai/HAM 100000/HAM10000_images_part_1.zip', '/content/drive/MyDrive/Skeenai/HAM 100000/HAM10000_images_part_2.zip']\n","extract_path = '/content/drive/MyDrive/Skeenai/HAM 100000/Extracted'\n","for zip_path in zip_paths:\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_path)\n","\n","# Load the metadata\n","metadata_path = '/content/drive/MyDrive/Skeenai/HAM 100000/HAM10000_metadata'\n","metadata = pd.read_csv(metadata_path)"],"metadata":{"id":"Wm2bbly7kwB2","executionInfo":{"status":"ok","timestamp":1722244300768,"user_tz":-420,"elapsed":284223,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Load images\n","def load_images(metadata, image_dir):\n","    images = []\n","    labels = []\n","    for index, row in metadata.iterrows():\n","        image_path = os.path.join(image_dir, row['image_id'] + '.jpg')\n","        if os.path.exists(image_path):\n","            image = cv2.imread(image_path)\n","            image = cv2.resize(image, (64, 64))  # Resize to 64x64 pixels\n","            images.append(image)\n","            labels.append(row['dx'])\n","    return np.array(images), np.array(labels)\n","\n","images, labels = load_images(metadata, extract_path)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","labels_encoded = label_encoder.fit_transform(labels)\n","labels_categorical = to_categorical(labels_encoded)"],"metadata":{"id":"xFt3KA2Kpy3a","executionInfo":{"status":"ok","timestamp":1722244449414,"user_tz":-420,"elapsed":148651,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Split dataset into training and testing\n","X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n","\n","# Build the model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(len(label_encoder.classes_), activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"],"metadata":{"id":"WU1bdCUBk1Oq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722244495996,"user_tz":-420,"elapsed":46597,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}},"outputId":"867b3690-b2d0-41eb-8e08-829771d0f8a5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","251/251 [==============================] - 10s 13ms/step - loss: 2.5566 - accuracy: 0.6444 - val_loss: 0.9307 - val_accuracy: 0.6695\n","Epoch 2/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.9746 - accuracy: 0.6736 - val_loss: 0.9069 - val_accuracy: 0.6625\n","Epoch 3/20\n","251/251 [==============================] - 2s 6ms/step - loss: 0.9100 - accuracy: 0.6735 - val_loss: 0.8870 - val_accuracy: 0.6645\n","Epoch 4/20\n","251/251 [==============================] - 2s 6ms/step - loss: 0.8916 - accuracy: 0.6852 - val_loss: 0.8964 - val_accuracy: 0.6790\n","Epoch 5/20\n","251/251 [==============================] - 2s 6ms/step - loss: 0.8583 - accuracy: 0.6882 - val_loss: 0.8579 - val_accuracy: 0.6885\n","Epoch 6/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.8354 - accuracy: 0.6938 - val_loss: 0.8570 - val_accuracy: 0.6870\n","Epoch 7/20\n","251/251 [==============================] - 2s 6ms/step - loss: 0.8308 - accuracy: 0.6982 - val_loss: 0.8780 - val_accuracy: 0.6940\n","Epoch 8/20\n","251/251 [==============================] - 2s 9ms/step - loss: 0.8250 - accuracy: 0.6990 - val_loss: 0.8245 - val_accuracy: 0.6940\n","Epoch 9/20\n","251/251 [==============================] - 2s 9ms/step - loss: 0.8015 - accuracy: 0.7061 - val_loss: 0.8301 - val_accuracy: 0.6975\n","Epoch 10/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.7831 - accuracy: 0.7107 - val_loss: 0.8797 - val_accuracy: 0.6800\n","Epoch 11/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.7596 - accuracy: 0.7179 - val_loss: 0.8277 - val_accuracy: 0.6990\n","Epoch 12/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.7477 - accuracy: 0.7260 - val_loss: 0.8669 - val_accuracy: 0.7019\n","Epoch 13/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.7392 - accuracy: 0.7264 - val_loss: 0.8103 - val_accuracy: 0.7074\n","Epoch 14/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.7195 - accuracy: 0.7336 - val_loss: 0.8050 - val_accuracy: 0.7064\n","Epoch 15/20\n","251/251 [==============================] - 2s 8ms/step - loss: 0.7285 - accuracy: 0.7272 - val_loss: 0.8467 - val_accuracy: 0.6950\n","Epoch 16/20\n","251/251 [==============================] - 2s 9ms/step - loss: 0.7130 - accuracy: 0.7334 - val_loss: 0.8114 - val_accuracy: 0.7049\n","Epoch 17/20\n","251/251 [==============================] - 2s 8ms/step - loss: 0.6892 - accuracy: 0.7379 - val_loss: 0.7730 - val_accuracy: 0.7179\n","Epoch 18/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.6657 - accuracy: 0.7524 - val_loss: 0.8428 - val_accuracy: 0.7064\n","Epoch 19/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.6771 - accuracy: 0.7471 - val_loss: 0.8276 - val_accuracy: 0.6955\n","Epoch 20/20\n","251/251 [==============================] - 2s 7ms/step - loss: 0.6571 - accuracy: 0.7531 - val_loss: 0.8721 - val_accuracy: 0.7029\n","63/63 [==============================] - 0s 3ms/step - loss: 0.8721 - accuracy: 0.7029\n","Test Accuracy: 70.29%\n"]}]},{"cell_type":"code","source":["# Predictions on the test set\n","y_pred = model.predict(X_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(y_test, axis=1)\n","\n","# Accuracy\n","accuracy = accuracy_score(y_true_classes, y_pred_classes)\n","\n","# Precision\n","precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n","\n","# Recall\n","recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n","\n","# F1 Score\n","f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n","\n","# F2 Score\n","f2 = fbeta_score(y_true_classes, y_pred_classes, beta=2, average='weighted')\n","\n","# F0.5 Score\n","f0_5 = fbeta_score(y_true_classes, y_pred_classes, beta=0.5, average='weighted')\n","\n","# Classification report\n","report = classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_)\n","\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","print(f\"Precision: {precision * 100:.2f}%\")\n","print(f\"Recall: {recall * 100:.2f}%\")\n","print(f\"F1 Score: {f1 * 100:.2f}%\")\n","print(f\"F2 Score: {f2 * 100:.2f}%\")\n","print(f\"F0.5 Score: {f0_5 * 100:.2f}%\")\n","print(\"\\nClassification Report:\\n\", report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiKpxAOzvLGE","executionInfo":{"status":"ok","timestamp":1722244496572,"user_tz":-420,"elapsed":594,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}},"outputId":"e453d6a2-c18a-45a6-fb78-7cd864c9e6b6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 0s 2ms/step\n","Accuracy: 70.29%\n","Precision: 63.50%\n","Recall: 70.29%\n","F1 Score: 64.74%\n","F2 Score: 67.77%\n","F0.5 Score: 62.97%\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","       akiec       0.00      0.00      0.00        69\n","         bcc       0.38      0.22      0.27        93\n","         bkl       0.38      0.36      0.37       228\n","          df       0.00      0.00      0.00        28\n","         mel       0.51      0.12      0.19       226\n","          nv       0.76      0.95      0.85      1338\n","        vasc       0.69      0.52      0.59        21\n","\n","    accuracy                           0.70      2003\n","   macro avg       0.39      0.31      0.33      2003\n","weighted avg       0.64      0.70      0.65      2003\n","\n"]}]},{"cell_type":"code","source":["# Define the save path\n","save_path = '/content/drive/MyDrive/Skeenai/HAM 100000/skin_disease_detection_model.h5'\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","\n","# Save the model\n","model.save(save_path)\n","\n","print(f\"Model saved to {save_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srYa1EGHubOf","executionInfo":{"status":"ok","timestamp":1722244496573,"user_tz":-420,"elapsed":5,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}},"outputId":"1ef20ca0-7a6d-4836-812b-c75336d5f9d1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved to /content/drive/MyDrive/Skeenai/HAM 100000/skin_disease_detection_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"markdown","source":["# **Skin Acne Detection**"],"metadata":{"id":"4HhwJdJC2aBr"}},{"cell_type":"code","source":["import os\n","import zipfile\n","import glob\n","import re\n","import json\n","import pandas as pd\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, classification_report\n","from tensorflow.keras.utils import to_categorical\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from google.colab import drive"],"metadata":{"id":"xXl4B7iy25X1","executionInfo":{"status":"ok","timestamp":1722246960378,"user_tz":-420,"elapsed":349,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Define paths\n","zip_path = '/content/drive/MyDrive/Skeenai/ACNE 04/ACNE04 (Manuel).zip'\n","extract_path = '/content/drive/MyDrive/Skeenai/ACNE 04/extracted'\n","small_1024_path = os.path.join(extract_path, 'acne_1024', 'small_1024')\n","renamed_image_dir = os.path.join(extract_path, 'acne_1024', 'small_1024_renamed')\n","save_path = os.path.join(extract_path, 'beauty_issues_detection_model.h5')\n","\n","# Extract the zip file\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","# Rename files based on a mapping\n","def rename_files(directory_path, rename_map):\n","    for filename in os.listdir(directory_path):\n","        if filename.endswith('.jpg'):\n","            for original, new in rename_map.items():\n","                if original in filename:\n","                    new_filename = filename.replace(original, new)\n","                    old_file_path = os.path.join(directory_path, filename)\n","                    new_file_path = os.path.join(directory_path, new_filename)\n","                    os.rename(old_file_path, new_file_path)\n","                    print(f'Renamed \"{filename}\" to \"{new_filename}\"')\n","                    break  # Stop checking after the first match\n","    print(\"Renaming complete.\")\n","\n","rename_map = {\n","    'acne0': 'acnezero',\n","    'acne1': 'acnesmall',\n","    'acne2': 'acnemedium',\n","    'acne3': 'acnestrong'\n","}\n","\n","rename_files(small_1024_path, rename_map)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J3p-gkln2eOv","executionInfo":{"status":"ok","timestamp":1722246988748,"user_tz":-420,"elapsed":27996,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}},"outputId":"a781ab55-8b3a-4191-9e27-16ee34ba5230"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Renaming complete.\n"]}]},{"cell_type":"code","source":["# Generate metadata.jsonl\n","def generate_metadata(image_dir):\n","    base_prompt = \"photo of a person with acne\"\n","    jpg_files = glob.glob(f\"{image_dir}/**/*.jpg\", recursive=True)\n","    metadata_list = []\n","\n","    for jpg_file in jpg_files:\n","        filename = jpg_file.split('/')[-1]\n","        match = re.search(r'(acnezero|acnesmall|acnemedium|acnestrong)', filename)\n","        if match:\n","            level = match.group(1)\n","            prompt = f\"{base_prompt} {level}\"\n","            entry = {\"file_name\": jpg_file, \"prompt\": prompt, \"level\": level}\n","            metadata_list.append(entry)\n","\n","    metadata_file_path = os.path.join(image_dir, 'metadata.jsonl')\n","    with open(metadata_file_path, 'w') as file:\n","        for entry in metadata_list:\n","            file.write(json.dumps(entry) + '\\n')\n","\n","    return metadata_file_path\n","\n","metadata_file_path = generate_metadata(renamed_image_dir)\n","\n","# Load metadata\n","def load_metadata(metadata_file_path):\n","    images = []\n","    labels = []\n","\n","    with open(metadata_file_path, 'r') as file:\n","        for line in file:\n","            entry = json.loads(line)\n","            image_path = entry[\"file_name\"]\n","            level = entry[\"level\"]\n","            if os.path.exists(image_path):\n","                image = cv2.imread(image_path)\n","                image = cv2.resize(image, (64, 64))  # Resize to 64x64 pixels\n","                images.append(image)\n","                labels.append(level)\n","\n","    return np.array(images), np.array(labels)\n","\n","images, labels = load_metadata(metadata_file_path)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","labels_encoded = label_encoder.fit_transform(labels)\n","labels_categorical = to_categorical(labels_encoded)"],"metadata":{"id":"rlWp3sUP3AaW","executionInfo":{"status":"ok","timestamp":1722246990318,"user_tz":-420,"elapsed":1572,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Split dataset into training and testing\n","X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n","\n","# Build the model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(len(label_encoder.classes_), activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcVhQI6V3CKp","executionInfo":{"status":"ok","timestamp":1722246993949,"user_tz":-420,"elapsed":3633,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}},"outputId":"7ecd25ea-57ed-4e93-d854-4bf945c0c3aa"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","5/5 [==============================] - 2s 132ms/step - loss: 38.2980 - accuracy: 0.2875 - val_loss: 4.2192 - val_accuracy: 0.3250\n","Epoch 2/20\n","5/5 [==============================] - 0s 13ms/step - loss: 8.4995 - accuracy: 0.2688 - val_loss: 2.4693 - val_accuracy: 0.2250\n","Epoch 3/20\n","5/5 [==============================] - 0s 17ms/step - loss: 2.0436 - accuracy: 0.3000 - val_loss: 1.3402 - val_accuracy: 0.4000\n","Epoch 4/20\n","5/5 [==============================] - 0s 13ms/step - loss: 1.3525 - accuracy: 0.3375 - val_loss: 1.4099 - val_accuracy: 0.3000\n","Epoch 5/20\n","5/5 [==============================] - 0s 12ms/step - loss: 1.2613 - accuracy: 0.4375 - val_loss: 1.4068 - val_accuracy: 0.3750\n","Epoch 6/20\n","5/5 [==============================] - 0s 16ms/step - loss: 1.1685 - accuracy: 0.4500 - val_loss: 1.4080 - val_accuracy: 0.3750\n","Epoch 7/20\n","5/5 [==============================] - 0s 16ms/step - loss: 1.0916 - accuracy: 0.5125 - val_loss: 1.4021 - val_accuracy: 0.3250\n","Epoch 8/20\n","5/5 [==============================] - 0s 17ms/step - loss: 1.0057 - accuracy: 0.6062 - val_loss: 1.4115 - val_accuracy: 0.4750\n","Epoch 9/20\n","5/5 [==============================] - 0s 15ms/step - loss: 0.8729 - accuracy: 0.6187 - val_loss: 1.4758 - val_accuracy: 0.4000\n","Epoch 10/20\n","5/5 [==============================] - 0s 17ms/step - loss: 0.8025 - accuracy: 0.6687 - val_loss: 1.7739 - val_accuracy: 0.4000\n","Epoch 11/20\n","5/5 [==============================] - 0s 16ms/step - loss: 0.6334 - accuracy: 0.7688 - val_loss: 1.8816 - val_accuracy: 0.3750\n","Epoch 12/20\n","5/5 [==============================] - 0s 14ms/step - loss: 0.5960 - accuracy: 0.7437 - val_loss: 1.7334 - val_accuracy: 0.3500\n","Epoch 13/20\n","5/5 [==============================] - 0s 15ms/step - loss: 0.5720 - accuracy: 0.7688 - val_loss: 1.9785 - val_accuracy: 0.4250\n","Epoch 14/20\n","5/5 [==============================] - 0s 12ms/step - loss: 0.4987 - accuracy: 0.8438 - val_loss: 2.2256 - val_accuracy: 0.4000\n","Epoch 15/20\n","5/5 [==============================] - 0s 19ms/step - loss: 0.3830 - accuracy: 0.8750 - val_loss: 2.1023 - val_accuracy: 0.4250\n","Epoch 16/20\n","5/5 [==============================] - 0s 16ms/step - loss: 0.3194 - accuracy: 0.9000 - val_loss: 2.0690 - val_accuracy: 0.4750\n","Epoch 17/20\n","5/5 [==============================] - 0s 14ms/step - loss: 0.3039 - accuracy: 0.8938 - val_loss: 2.3866 - val_accuracy: 0.4250\n","Epoch 18/20\n","5/5 [==============================] - 0s 13ms/step - loss: 0.2925 - accuracy: 0.9187 - val_loss: 2.5502 - val_accuracy: 0.4750\n","Epoch 19/20\n","5/5 [==============================] - 0s 17ms/step - loss: 0.2666 - accuracy: 0.9250 - val_loss: 2.9023 - val_accuracy: 0.4750\n","Epoch 20/20\n","5/5 [==============================] - 0s 12ms/step - loss: 0.2087 - accuracy: 0.9438 - val_loss: 2.7067 - val_accuracy: 0.4000\n"]}]},{"cell_type":"code","source":["# Evaluate the model\n","y_pred = model.predict(X_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(y_test, axis=1)\n","\n","# Metrics calculation\n","accuracy = accuracy_score(y_true_classes, y_pred_classes)\n","precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n","recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n","f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n","f2 = fbeta_score(y_true_classes, y_pred_classes, beta=2, average='weighted')\n","f0_5 = fbeta_score(y_true_classes, y_pred_classes, beta=0.5, average='weighted')\n","classification_report_str = classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_)\n","\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","print(f\"Precision: {precision * 100:.2f}%\")\n","print(f\"Recall: {recall * 100:.2f}%\")\n","print(f\"F1 Score: {f1 * 100:.2f}%\")\n","print(f\"F2 Score: {f2 * 100:.2f}%\")\n","print(f\"F0.5 Score: {f0_5 * 100:.2f}%\")\n","print(\"\\nClassification Report:\\n\", classification_report_str)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8anNmOQ7TFq","executionInfo":{"status":"ok","timestamp":1722247101852,"user_tz":-420,"elapsed":380,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}},"outputId":"801098cc-5a6f-4841-da0e-fbabf58b837f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 7ms/step\n","Accuracy: 40.00%\n","Precision: 38.91%\n","Recall: 40.00%\n","F1 Score: 37.66%\n","F2 Score: 38.48%\n","F0.5 Score: 38.07%\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","  acnemedium       0.25      0.17      0.20         6\n","   acnesmall       0.50      0.40      0.44        15\n","  acnestrong       0.41      0.78      0.54         9\n","    acnezero       0.29      0.20      0.24        10\n","\n","    accuracy                           0.40        40\n","   macro avg       0.36      0.39      0.35        40\n","weighted avg       0.39      0.40      0.38        40\n","\n"]}]},{"cell_type":"code","source":["# Define the save path\n","save_path = os.path.join(extract_path, 'beauty_issues_detection_model.h5')\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","\n","# Save the model\n","model.save(save_path)\n","\n","print(f\"Model saved to {save_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4NglrPn3Lxy","executionInfo":{"status":"ok","timestamp":1722246994313,"user_tz":-420,"elapsed":366,"user":{"displayName":"Malik Alrasyid Basori","userId":"00176157117110441047"}},"outputId":"6675685d-cd9b-47b2-c3b8-3af6f02ec219"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved to /content/drive/MyDrive/Skeenai/ACNE 04/extracted/beauty_issues_detection_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]}]}